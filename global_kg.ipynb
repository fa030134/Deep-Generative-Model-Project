{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    FieldSchema,\n",
    "    DataType,\n",
    ")\n",
    "\n",
    "# 创建到Milvus服务器的连接\n",
    "connections.connect(\"default\", host=\"\", port=\"\")\n",
    "# 获取所有的集合名称\n",
    "collection_names=utility.list_collections()\n",
    "print(collection_names)\n",
    "\n",
    "search_res_list=[]\n",
    "# 遍历所有的集合\n",
    "for collection_name in collection_names:\n",
    "    print(f\"Collection: {collection_name}\")\n",
    "\n",
    "    # 获取集合对象\n",
    "    collection = Collection(collection_name)\n",
    "    collection.load()\n",
    "\n",
    "    dim=768  #m3e-base生成768维向量\n",
    "    query_vector = np.random.rand(1, dim).tolist()\n",
    "    search_params = {\n",
    "        \"metric_type\": \"IP\",\n",
    "        \"params\": {\"nprobe\": 20}\n",
    "    }\n",
    "    topk=16384\n",
    "    results = collection.search(\n",
    "        data=query_vector,\n",
    "        anns_field=\"index_vector\",\n",
    "        param=search_params,\n",
    "        limit=topk,\n",
    "        output_fields=[\"content\", \"metadata\"]\n",
    "    )\n",
    "    print(results)\n",
    "\n",
    "\n",
    "    for hits in results:\n",
    "        for hit in hits:\n",
    "            entity = hit.to_dict()['entity']\n",
    "            search_res_list.append(entity['content'])\n",
    "            print(entity['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据搜索结果构建知识图谱\n",
    "#不要随意运行本部分\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from py2neo import NodeMatcher, RelationshipMatcher\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "graph=Graph('http://localhost:7474')\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_md\")\n",
    "\n",
    "patterns = r'。|？|！|（|）|；|\\r'\n",
    "\n",
    "for search_text in search_res_list:\n",
    "    lines = re.split(patterns,search_text)\n",
    "    for line in tqdm(lines):\n",
    "        #print(line)\n",
    "        line_node=Node(\"TEXT\",text=line)\n",
    "        graph.merge(line_node,\"TEXT\",\"text\")\n",
    "        if line!=\"\":\n",
    "            doc=nlp(line)\n",
    "            # for token in doc:\n",
    "            #     #print(token.text,token.pos_,token.tag_)\n",
    "            #     print(token.text,token.dep_,token.head)\n",
    "            # for chunk in doc.noun_chunks:\n",
    "            #     print(chunk.text)\n",
    "            #print(\"===========================\")\n",
    "            for ent in doc.ents:\n",
    "                #print (ent.text, ent.label_)\n",
    "                ent_node=Node(ent.label_,text=ent.text)\n",
    "                graph.merge(ent_node,ent.label_,\"text\")\n",
    "                relation=Relationship(line_node,\"include\",ent_node)\n",
    "                graph.create(relation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query实体获取\n",
    "import spacy\n",
    "nlp = spacy.load(\"zh_core_web_md\")\n",
    "\n",
    "text=[user_query]\n",
    "entity_list=[]\n",
    "for onetext in text:\n",
    "    doc=nlp(onetext)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent not in entity_list:\n",
    "            #print (ent.text, ent.label_)\n",
    "            entity_list.append(ent.text)\n",
    "\n",
    "print(entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#搜索全局知识图谱\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from py2neo import NodeMatcher, RelationshipMatcher\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "graph=Graph('http://222.29.98.160:7475')\n",
    "node_matcher = NodeMatcher(graph)\n",
    "relationship_matcher = RelationshipMatcher(graph)\n",
    "\n",
    "\n",
    "text_list = []\n",
    "\n",
    "for entity in entity_list:\n",
    "    doc=nlp(entity)\n",
    "    for ent in doc.ents:\n",
    "        print (ent.text, ent.label_)\n",
    "        query_ent_node = node_matcher.match(ent.label_,text=ent.text).first()\n",
    "        relationships = list(relationship_matcher.match((None,query_ent_node), r_type=None))\n",
    "        #print(relationships)\n",
    "        for relationship in relationships:\n",
    "            #node_text=relationship.end_node[\"text\"]\n",
    "            node_text=relationship.start_node[\"text\"]\n",
    "            if node_text not in text_list:\n",
    "                print(node_text)\n",
    "                text_list.append(node_text)\n",
    "        # if ent.text not in text_list:\n",
    "        #     text_list.append(ent.text)\n",
    "\n",
    "text_chunk=\"\"\n",
    "for text in text_list:\n",
    "    text_chunk+=text\n",
    "\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#手动增加实体\n",
    "#搜索临时知识图谱\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from py2neo import NodeMatcher, RelationshipMatcher\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "graph=Graph('http://222.29.98.73:7474')\n",
    "node_matcher = NodeMatcher(graph)\n",
    "relationship_matcher = RelationshipMatcher(graph)\n",
    "\n",
    "\n",
    "new_entity=[]\n",
    "\n",
    "for entity in new_entity:\n",
    "    cypher_ = \"Match  (a)  where  a.text Contains  '{ent}' return  a\".format(ent=entity)\n",
    "    #print(cypher_)\n",
    "    df = graph.run(cypher_).data()#.to_data_frame() # pd.DataFrame\n",
    "    print(df)\n",
    "    for i in df:\n",
    "        print(i['a']['text'])\n",
    "\n",
    "text_chunk=\"\"\n",
    "for text in text_list:\n",
    "    text_chunk+=text\n",
    "\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用大语言模型回答\n",
    "import openai\n",
    "\n",
    "openai.api_base = ''\n",
    "openai.api_key = ''\n",
    "\n",
    "augment_query=\"问题：\"+ user_query + \"\\n\"\n",
    "augment_query+=\"相关资料：\"+text_chunk\n",
    "history=[]\n",
    "history.append({\"role\": \"user\", \"content\": augment_query})\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "            model='',\n",
    "            messages=history,\n",
    "            temperature=0.2\n",
    "        )\n",
    "\n",
    "answer= response.choices[0].message.content\n",
    "\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Askpku",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
